{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adjustable-theater",
   "metadata": {},
   "source": [
    "# Experiments with Telco Churn data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-romance",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to build a ML model for telco churn data. We are going to build a basic model using scikit learn. The purpose is to experiment with feature engineering and different models. Once we are happy with the result we are going to package our code and execute this on AI platform training service.\n",
    "\n",
    "Before you execute the following, please replace the PROJECT variable with your project id. The project id can be found on your GCP console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-baghdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT=!gcloud config get-value project # returns default project id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-miller",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT=PROJECT[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-confidence",
   "metadata": {},
   "source": [
    "## Loading data from BigQuery to Pandas Dataframe\n",
    "\n",
    "In the following cell we are pulling data from BQ and loading them to a dataframe. Keep in mind that data might not fit your instance memory and therefore we might need to only bring a sample of the data. That is not a big problem as we are only experimenting. When we will be running our training job on AI Platform training we need to pick the right instance with enough memory.\n",
    "\n",
    "Additionally our telco dataset fits the memory so we will go ahead and load everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.auth\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import bigquery_storage\n",
    "\n",
    "# Make clients.\n",
    "bqclient = bigquery.Client(project=PROJECT)\n",
    "bqstorageclient = bigquery_storage.BigQueryReadClient()\n",
    "query_string = \"\"\"\n",
    "SELECT * from telco.churn\n",
    "\"\"\"\n",
    "\n",
    "df = (\n",
    "    bqclient.query(query_string)\n",
    "    .result()\n",
    "    .to_dataframe(bqstorage_client=bqstorageclient)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-weekend",
   "metadata": {},
   "source": [
    "Let's have a look how the data loaded in the dataframe look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-isolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-insight",
   "metadata": {},
   "source": [
    "## Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-keyboard",
   "metadata": {},
   "source": [
    "It seems that there are some invalid values in TotalCharges column where the TotalCharges is missing. Look at the first record below, data are order based on TotalCharges.\n",
    "\n",
    "Why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"TotalCharges\", ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-heath",
   "metadata": {},
   "source": [
    "hm... I suspect that the reason is that new customers do not have TotalCharges as this is their first month..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['tenure']==0, ['tenure', 'MonthlyCharges', 'TotalCharges']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-manner",
   "metadata": {},
   "source": [
    "Okey lets fix this by assigning the values of this column to the same as MonthlyCharges. For new customers at the end of the first month the total charges should be the same as that month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-notification",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.tenure == 0, 'TotalCharges'] = df.loc[df.tenure == 0, 'MonthlyCharges']\n",
    "df.loc[df.tenure==0, ['tenure', 'MonthlyCharges', 'TotalCharges']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-immune",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "We have columns in multible formats. Some are numerical, some are categorical(0 or 1) and some are categorical with multiple options.\n",
    "There is also customerID that we do not really need. It is uniqu to the customer and it should not be part of the prediction equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "BINARY_FEATURES = ['gender',\n",
    "            'SeniorCitizen',\n",
    "            'Partner',\n",
    "            'Dependents',\n",
    "            'PhoneService',\n",
    "            'MultipleLines',\n",
    "            'PaperlessBilling']\n",
    "\n",
    "NUMERIC_FEATURES = [\n",
    "            'tenure',\n",
    "            'MonthlyCharges',\n",
    "            'TotalCharges']\n",
    "\n",
    "CATEGORICAL_FEATURES = [\n",
    "            'InternetService',\n",
    "            'OnlineSecurity',\n",
    "            'DeviceProtection',\n",
    "            'TechSupport',\n",
    "            'StreamingTV',\n",
    "            'StreamingMovies',\n",
    "            'Contract',\n",
    "            'PaymentMethod']\n",
    "\n",
    "# all rows but only selected features/columns\n",
    "X = df.loc[:, BINARY_FEATURES+NUMERIC_FEATURES+CATEGORICAL_FEATURES]\n",
    "\n",
    "# We create a series with the prediciton label\n",
    "y = df.Churn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-iraqi",
   "metadata": {},
   "source": [
    "Now we are going to perform opperations to our features, to OneHotEncode and to scaling to unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-petite",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Definining a preprocessing step for our pipeline. \n",
    "# it specifies how the features are going to be transformed\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('bin', OneHotEncoder(sparse=False), BINARY_FEATURES),\n",
    "        ('num', StandardScaler(), NUMERIC_FEATURES),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), CATEGORICAL_FEATURES)])\n",
    "\n",
    "\n",
    "# We now create a full pipeline, for preprocessing and training.\n",
    "# for training we selected a linear SVM classifier\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', SVC(kernel='linear'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-search",
   "metadata": {},
   "source": [
    "We are going to split our data to  80% training and 20% test sets, and we will traing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-immigration",
   "metadata": {},
   "source": [
    "## Training ML model\n",
    "In the next step we are going to train our model and predict on the test data. We will then use the predictions to evaluate our model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-injury",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-facial",
   "metadata": {},
   "source": [
    "## Evaluating model\n",
    "What do you think of this model? Is it accurate enough? Shall we move this into production?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-porcelain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt  \n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "print(\"\\n Confusion Matrix\")\n",
    "plot_confusion_matrix(clf, X_test,y_test)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.mnightly-2021-02-02-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:mnightly-2021-02-02-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

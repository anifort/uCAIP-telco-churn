{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "minus-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import logging\n",
    "\n",
    "bq_location = 'EU'\n",
    "bq_project_id = \"myfirstproject-226013\"\n",
    "bq_staging_table_uri = \"myfirstproject-226013.telco.tmp-table-v5\"\n",
    "BUCKET_NAME = \"gs://feature-store-mars21\"\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT customerID as customer,TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 1 DAY)  as timestamp, Churn as label\n",
    "        FROM `myfirstproject-226013.telco.churn` WHERE 1=1\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "client = bigquery.Client(project=bq_project_id, location=bq_location,)\n",
    "\n",
    "overwrite_table = False\n",
    "job_config = bigquery.QueryJobConfig(\n",
    "    write_disposition = bigquery.job.WriteDisposition.WRITE_TRUNCATE if overwrite_table else bigquery.job.WriteDisposition.WRITE_EMPTY,\n",
    "    destination = bq_staging_table_uri)\n",
    "\n",
    "try:\n",
    "    query_job = client.query(query = query, \n",
    "                             job_config = job_config)\n",
    "    query_job.result()\n",
    "    #if .total_rows == 0:\n",
    "    #    raise Exception(\"Query return no rows\".format(bq_staging_table_uri))\n",
    "\n",
    "    if query_job.errors: \n",
    "        raise Exception() \n",
    "except Exception as e:\n",
    "    logging.error(query_job.errors)\n",
    "    raise e\n",
    "\n",
    "table_dataset_metadata={}\n",
    "\n",
    "table = client.get_table(bq_staging_table_uri)  # Make an API request.\n",
    "table_dataset_path = \"bq://{}\".format(bq_staging_table_uri)\n",
    "table_dataset_metadata['table_name'] = bq_staging_table_uri\n",
    "\n",
    "\n",
    "\n",
    "if table.num_rows==0:\n",
    "    raise Exception(\"BQ table {} has no rows. Ensure thet your query returns results: {}\".format(bq_query_data_table, query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "applicable-alarm",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict # in case dict is not created using python>=3.6\n",
    "schema = OrderedDict((i.name,i.field_type) for i in table.schema)\n",
    "entity_type_cols = []\n",
    "pass_through_cols = []\n",
    "found_timestamp=False\n",
    "for key, value in schema.items():\n",
    "    if key=='timestamp':\n",
    "        found_timestamp=True\n",
    "        if value!=\"TIMESTAMP\":\n",
    "            raise ValueError(\"timestamp column must be of type TIMESTAMP\")\n",
    "    else:\n",
    "        if found_timestamp==False:\n",
    "            entity_type_cols.append(key)\n",
    "        else:\n",
    "            pass_through_cols.append(key)\n",
    "        \n",
    "if found_timestamp==False: # means timestamp column was not found so this remained False\n",
    "    raise ValueError(\"timestamp column missing from BQ table. It is required for feature store data retrieval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "recorded-plasma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['customer']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_type_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "informal-healing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pass_through_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "expressed-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_location = 'europe-west4'\n",
    "fs_project = 'myfirstproject-226013'\n",
    "fs_featurestore_name = 'telco'\n",
    "\n",
    "fs_path= 'projects/{fs_project}/locations/{fs_location}/featurestores/{fs_name}'.format(fs_project=fs_project,\n",
    "                                                   fs_location=fs_location,\n",
    "                                                   fs_name=fs_featurestore_name)\n",
    "    \n",
    "from google.cloud.aiplatform_v1beta1 import FeaturestoreServiceClient\n",
    "\n",
    "API_ENDPOINT = \"{}-aiplatform.googleapis.com\".format(fs_location)\n",
    "\n",
    "admin_client = FeaturestoreServiceClient(\n",
    "    client_options={\"api_endpoint\": API_ENDPOINT})\n",
    "\n",
    "fs_entities = admin_client.list_entity_types(parent=fs_path).entity_types\n",
    "\n",
    "fs_entities = [i.name.split('/')[-1] for i in fs_entities]\n",
    "\n",
    "if len(set(entity_type_cols).difference(fs_entities))>0:\n",
    "    raise ValueError(\"Table column(s) {} before timestamp column do not match entities in feature store {} \".format(entity_type_cols, fs_entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "naughty-corruption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['customer']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_type_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "distributed-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_features  = {'customer': [\"tenure\", \"monthly_charges\", \"internet_service\"]}\n",
    "entities_diff = set(my_features.keys()).difference(entity_type_cols)\n",
    "if len(entities_diff)>0:\n",
    "    raise LookupError(\"\\n Entities {} must exist in filtering query columns: {} \".format(entities_diff, query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "athletic-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_buffer = \"\"\n",
    "for k,v in my_features.items():\n",
    "    fs_features = admin_client.list_features(parent=fs_path+\"/entityTypes/{}\".format(k)).features\n",
    "    fs_features = [i.name.split('/')[-1] for i in fs_features]\n",
    "    \n",
    "    missing_features = set(v).difference(fs_features)\n",
    "    if len(missing_features)>0:\n",
    "        error_buffer += \"\\n Features requested for entity [{}] do not exist: {}\".format(k, missing_features)\n",
    "        \n",
    "if error_buffer!=\"\":\n",
    "    raise LookupError(error_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "stone-convenience",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bq_export_table_uri=\"myfirstproject-226013.telco.features-table-v5\"\n",
    "\n",
    "from google.cloud.aiplatform_v1beta1.types import (featurestore_service as featurestore_service_pb2,\n",
    "                                                   feature_selector as feature_selector_pb2,\n",
    "                                                   BigQuerySource, BigQueryDestination)\n",
    "entity_type_specs_arr=[]\n",
    "\n",
    "# Select features to read\n",
    "for ent_type, features_arr in my_features.items():\n",
    "    entity_type_specs_arr.append(\n",
    "        featurestore_service_pb2.BatchReadFeatureValuesRequest.EntityTypeSpec(\n",
    "            # read feature values of features subscriber_type and duration_minutes from \"bikes\"\n",
    "            entity_type_id= ent_type, \n",
    "            feature_selector= feature_selector_pb2.FeatureSelector(\n",
    "                id_matcher=feature_selector_pb2.IdMatcher(\n",
    "                ids=features_arr))\n",
    "        )\n",
    "    )\n",
    "    \n",
    "# Select columns to pass through\n",
    "\n",
    "pass_through_fields_arr = []\n",
    "for ptc in pass_through_cols:\n",
    "    pass_through_fields_arr.append(\n",
    "        featurestore_service_pb2.BatchReadFeatureValuesRequest.PassThroughField(\n",
    "            # read feature values of features subscriber_type and duration_minutes from \"bikes\"\n",
    "            field_name=ptc\n",
    "        )\n",
    "    )\n",
    "   \n",
    "batch_serving_request = featurestore_service_pb2.BatchReadFeatureValuesRequest(\n",
    "    featurestore=fs_path,\n",
    "    bigquery_read_instances=BigQuerySource(input_uri = \"bq://{}\".format(bq_staging_table_uri)),\n",
    "    #csv_read_instances=io_pb2.CsvSource(\n",
    "    #    gcs_source=io_pb2.GcsSource(uris=[FEATURE_REQ_CSV_PATH])),\n",
    "    \n",
    "    # Output info\n",
    "    destination=featurestore_service_pb2.FeatureValueDestination(\n",
    "        bigquery_destination=BigQueryDestination(\n",
    "            # output to BigQuery table\n",
    "            output_uri='bq://{}'.format(bq_export_table_uri))),\n",
    "    #destination=featurestore_service_pb2.FeatureValueDestination(\n",
    "    #    tfrecord_destination=io_pb2.CsvDestination(\n",
    "    #        gcs_destination=EXPORT_TF_PATH)),\n",
    "    \n",
    "    entity_type_specs=entity_type_specs_arr,\n",
    "    pass_through_fields=pass_through_fields_arr\n",
    "\n",
    "    \n",
    ")\n",
    "\n",
    "try:\n",
    "    print(admin_client.batch_read_feature_values(batch_serving_request).result(timeout=600))\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-supervisor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.mnightly-2021-02-02-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:mnightly-2021-02-02-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
